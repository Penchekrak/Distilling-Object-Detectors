{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "written-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torchvision.datasets import VOCDetection\n",
    "from torchvision.transforms import Compose, Resize, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "arabic-warning",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpenchekrak\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">logical-frost-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/penchekrak/test\" target=\"_blank\">https://wandb.ai/penchekrak/test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/penchekrak/test/runs/54p7e45l\" target=\"_blank\">https://wandb.ai/penchekrak/test/runs/54p7e45l</a><br/>\n",
       "                Run data is saved locally in <code>/home/annispiridonov/RESEARCH_PRACTICE/examples/wandb/run-20210302_163441-54p7e45l</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(54p7e45l)</h1><iframe src=\"https://wandb.ai/penchekrak/test/runs/54p7e45l\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f3087823278>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "characteristic-approach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/VOCtrainval_06-Nov-2007.tar\n"
     ]
    }
   ],
   "source": [
    "img_size = (512, 512)\n",
    "\n",
    "def target_transform(target):\n",
    "    size = float(target['annotation']['size']['width']), float(target['annotation']['size']['height']) \n",
    "    label = [float(target['annotation']['object'][0]['bndbox'][coord]) for coord in ['xmin', 'ymin', 'xmax', 'ymax']] \n",
    "    label[0] /= size[0]\n",
    "    label[2] /= size[0]\n",
    "    label[1] /= size[1]\n",
    "    label[3] /= size[1]\n",
    "    return torch.Tensor(label)\n",
    "dataset = VOCDetection(\n",
    "    root='../data',\n",
    "    download=True,\n",
    "    year='2007',\n",
    "    image_set='val',\n",
    "    transform=Compose([Resize(img_size), ToTensor()]),\n",
    "    target_transform=target_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "existing-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "static-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "patient-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-commodity",
   "metadata": {},
   "source": [
    "Object detection tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pleased-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "class DummyDetector(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 10, kernel_size=3, padding=1)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(10, 4, kernel_size=512)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.sigm = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.flatten(self.conv2(self.act1(self.conv1(x)))))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        outs = self(x)\n",
    "        loss = F.mse_loss(outs, y)\n",
    "        self.logger.experiment.log({'image': wandb.Image(\n",
    "            x[0].permute(1, 2, 0).detach().cpu().numpy(),\n",
    "            boxes={\n",
    "    \"predictions\": {\n",
    "        \"box_data\": [{\n",
    "            \"position\": {\n",
    "                \"minX\": outs[0][0].item(),\n",
    "                \"maxX\": outs[0][2].item(),\n",
    "                \"minY\": outs[0][1].item(),\n",
    "                \"maxY\": outs[0][3].item(),\n",
    "            },\n",
    "            \"class_id\" : 0,\n",
    "            \"box_caption\": \"box\",\n",
    "            \"scores\" : {\n",
    "                \"acc\": 0,\n",
    "                \"loss\": 0\n",
    "            },\n",
    "        },\n",
    "        ],\n",
    "        \"class_labels\": {0: 'box'}\n",
    "    }\n",
    "        }),\n",
    "    'train_loss': loss.item()\n",
    "    })\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pacific-slovak",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | conv1   | Conv2d  | 280   \n",
      "1 | act1    | ReLU    | 0     \n",
      "2 | conv2   | Conv2d  | 10.5 M\n",
      "3 | flatten | Flatten | 0     \n",
      "4 | sigm    | Sigmoid | 0     \n",
      "------------------------------------\n",
      "10.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.5 M    Total params\n",
      "41.944    Total estimated model params size (MB)\n",
      "/data/annispiridonov/research_practice_venv/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 72 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc8b0f7a9da4169a4fb07bd5763c6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/annispiridonov/research_practice_venv/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "model = DummyDetector()\n",
    "trainer = Trainer(logger=WandbLogger(), gpus=1)\n",
    "trainer.fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accessory-attempt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1.], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-windsor",
   "metadata": {},
   "source": [
    "Distillation Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
